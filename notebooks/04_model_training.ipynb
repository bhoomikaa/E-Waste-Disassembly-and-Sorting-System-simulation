{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 — Model Training & Analysis\n",
    "\n",
    "Train the hierarchical VLA models and analyze results.\n",
    "\n",
    "1. Train Level 2 (Skill Selector) via behavioral cloning\n",
    "2. Train Level 3 (Motor Policy) via diffusion\n",
    "3. Visualize training curves\n",
    "4. Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "if device == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 — Model Architecture Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safedisassemble.models.skill_selector.selector import SkillSelector, SKILL_VOCAB\n",
    "from safedisassemble.models.motor_policy.diffusion_policy import DiffusionMotorPolicy\n",
    "\n",
    "# Level 2: Skill Selector\n",
    "selector = SkillSelector(image_size=84, embed_dim=256)\n",
    "selector_params = sum(p.numel() for p in selector.parameters())\n",
    "print(f\"Skill Selector: {selector_params:,} parameters\")\n",
    "print(f\"  Skills: {SKILL_VOCAB}\")\n",
    "\n",
    "# Level 3: Motor Policy\n",
    "policy = DiffusionMotorPolicy(\n",
    "    action_dim=7, action_horizon=16, image_size=84,\n",
    "    cond_dim=256, num_diffusion_steps=100, num_inference_steps=10,\n",
    ")\n",
    "policy_params = sum(p.numel() for p in policy.parameters())\n",
    "print(f\"\\nMotor Policy: {policy_params:,} parameters\")\n",
    "print(f\"  Action horizon: 16 steps\")\n",
    "print(f\"  Diffusion steps (train): 100\")\n",
    "print(f\"  Diffusion steps (inference): 10\")\n",
    "\n",
    "print(f\"\\nTotal parameters: {selector_params + policy_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 — Forward Pass Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = selector.to(device)\n",
    "policy = policy.to(device)\n",
    "\n",
    "# Test Skill Selector\n",
    "batch = {\n",
    "    'images': torch.randn(4, 3, 84, 84).to(device),\n",
    "    'tokens': torch.randint(0, 1000, (4, 32)).to(device),\n",
    "    'proprio': torch.randn(4, 19).to(device),\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = selector(batch['images'], batch['tokens'], batch['proprio'])\n",
    "    print('Skill Selector output:')\n",
    "    print(f'  skill_logits: {out[\"skill_logits\"].shape}')\n",
    "    print(f'  skill_params: {out[\"skill_params\"].shape}')\n",
    "    print(f'  confidence:   {out[\"confidence\"].shape}')\n",
    "    print(f'  Predicted skills: {[SKILL_VOCAB[i] for i in out[\"skill_logits\"].argmax(dim=1)]}')\n",
    "\n",
    "# Test Motor Policy\n",
    "skill_ids = torch.randint(0, 8, (4,)).to(device)\n",
    "skill_params = torch.randn(4, 10).to(device)\n",
    "\n",
    "loss = policy.compute_loss(\n",
    "    batch['images'], batch['proprio'], skill_ids, skill_params,\n",
    "    torch.randn(4, 16, 7).to(device),\n",
    ")\n",
    "print(f'\\nMotor Policy diffusion loss: {loss.item():.4f}')\n",
    "\n",
    "actions = policy.predict_action(\n",
    "    batch['images'], batch['proprio'], skill_ids, skill_params,\n",
    ")\n",
    "print(f'Predicted actions: {actions.shape}  (batch, horizon, action_dim)')\n",
    "print(f'Action range: [{actions.min():.3f}, {actions.max():.3f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 — Training (Small-Scale Demo)\n",
    "\n",
    "For full training, use `scripts/train.py`. This cell runs a quick overfit test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick overfit test on a small batch\n",
    "selector = SkillSelector(image_size=84, embed_dim=128).to(device)\n",
    "optimizer = torch.optim.Adam(selector.parameters(), lr=1e-3)\n",
    "\n",
    "# Fixed batch to overfit on\n",
    "fixed_batch = {\n",
    "    'images': torch.randn(8, 3, 84, 84).to(device),\n",
    "    'tokens': torch.randint(0, 1000, (8, 32)).to(device),\n",
    "    'proprio': torch.randn(8, 19).to(device),\n",
    "    'skill_target': torch.randint(0, len(SKILL_VOCAB), (8,)).to(device),\n",
    "    'param_target': torch.randn(8, 10).to(device),\n",
    "}\n",
    "\n",
    "losses = []\n",
    "for step in range(200):\n",
    "    out = selector(fixed_batch['images'], fixed_batch['tokens'], fixed_batch['proprio'])\n",
    "    loss_dict = selector.compute_loss(out, fixed_batch['skill_target'], fixed_batch['param_target'])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss_dict['total_loss'].backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss_dict['total_loss'].item())\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Skill Selector — Overfit Test (should go to ~0)')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f'Final loss: {losses[-1]:.6f}')\n",
    "print(f'Loss decreased: {losses[0]:.4f} -> {losses[-1]:.6f} ({losses[0]/losses[-1]:.0f}x reduction)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 — Visualize Diffusion Denoising Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safedisassemble.models.motor_policy.diffusion_policy import DiffusionScheduler\n",
    "\n",
    "scheduler = DiffusionScheduler(num_train_steps=100)\n",
    "\n",
    "# Show the noise schedule\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(scheduler.betas.numpy())\n",
    "axes[0].set_title('Beta Schedule')\n",
    "axes[0].set_xlabel('Timestep')\n",
    "\n",
    "axes[1].plot(scheduler.alphas_cumprod.numpy())\n",
    "axes[1].set_title('Cumulative Alpha (signal remaining)')\n",
    "axes[1].set_xlabel('Timestep')\n",
    "\n",
    "axes[2].plot(scheduler.sqrt_one_minus_alphas_cumprod.numpy())\n",
    "axes[2].set_title('Noise Level')\n",
    "axes[2].set_xlabel('Timestep')\n",
    "\n",
    "plt.suptitle('DDPM Noise Schedule (cosine)', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize progressive noising of an action trajectory\n",
    "original_actions = torch.sin(torch.linspace(0, 4*np.pi, 16)).unsqueeze(0).unsqueeze(0).repeat(1, 7, 1)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(18, 6))\n",
    "timesteps_to_show = [0, 10, 25, 50, 99]\n",
    "\n",
    "for i, t in enumerate(timesteps_to_show):\n",
    "    noise = torch.randn_like(original_actions)\n",
    "    noisy = scheduler.add_noise(original_actions, noise, torch.tensor([t]))\n",
    "    \n",
    "    axes[0, i].plot(original_actions[0, 0].numpy(), 'b-', alpha=0.3, label='original')\n",
    "    axes[0, i].plot(noisy[0, 0].numpy(), 'r-', label='noisy')\n",
    "    axes[0, i].set_title(f't = {t}')\n",
    "    axes[0, i].set_ylim(-3, 3)\n",
    "    if i == 0:\n",
    "        axes[0, i].legend(fontsize=8)\n",
    "    \n",
    "    axes[1, i].plot(noise[0, 0].numpy(), 'g-', alpha=0.5, label='target noise')\n",
    "    axes[1, i].set_ylim(-3, 3)\n",
    "    if i == 0:\n",
    "        axes[1, i].set_ylabel('Noise to predict')\n",
    "\n",
    "axes[0, 0].set_ylabel('Action trajectory')\n",
    "plt.suptitle('Forward Diffusion: Progressive Noising of Action Trajectories', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
